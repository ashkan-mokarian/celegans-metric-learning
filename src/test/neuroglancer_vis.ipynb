{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://127.0.0.1:12345/v/8ec2ab6e5a0a3fa144a7e0f9c6e0f506fc5d3811/\" target=\"_blank\">Viewer</a>"
      ],
      "text/plain": [
       "http://127.0.0.1:12345/v/8ec2ab6e5a0a3fa144a7e0f9c6e0f506fc5d3811/"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neuroglancer\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "neuroglancer.set_server_bind_address('127.0.0.1', '12345')\n",
    "viewer = neuroglancer.Viewer()\n",
    "dimensions = neuroglancer.CoordinateSpace(\n",
    "    names=['x', 'y', 'z'],\n",
    "    units='',\n",
    "    scales=[1, 1, 1])\n",
    "with viewer.txn() as s:\n",
    "    s.dimensions = dimensions\n",
    "viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw (140, 140, 1166) 0.0 1.0\n",
      "gt_label (140, 140, 1166) 0 533\n"
     ]
    }
   ],
   "source": [
    "wormhdf_fn = '/home/ashkan/workspace/deployed/worms_nuclei_metric_learning-deployed/' +\\\n",
    "             'experiments/inst_seg/output76-2/pred/masked-bw=2-bestmodel-step=49000-running_loss=2/worm04.hdf'\n",
    "with h5py.File(wormhdf_fn, 'r') as f:\n",
    "    raw = f['raw'][()].astype('float32')\n",
    "    gt_label = f['label'][()].astype('uint32')  # if in uint format, recognizes as labels\n",
    "raw = raw / raw.max()\n",
    "print('raw', raw.shape, raw.min(), raw.max())\n",
    "print('gt_label', gt_label.shape, gt_label.min(), gt_label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for raw data\n",
    "with viewer.txn() as s:\n",
    "    s.layers.append(\n",
    "            name='raw',\n",
    "            layer=neuroglancer.LocalVolume(\n",
    "                data=raw,\n",
    "                volume_type='image',\n",
    "                dimensions=neuroglancer.CoordinateSpace(\n",
    "                    names=['x', 'y', 'z'],\n",
    "                    units=['', '', ''],\n",
    "                    scales=[1, 1, 1],\n",
    "                    coordinate_arrays=[\n",
    "                    None, None, None\n",
    "                ]),\n",
    "            voxel_offset=(0, 0, 0)\n",
    "    ))\n",
    "    \n",
    "# for gt label\n",
    "with viewer.txn() as s:\n",
    "    s.layers.append(\n",
    "            name='gt_label',\n",
    "            layer=neuroglancer.LocalVolume(\n",
    "                data=gt_label,\n",
    "                volume_type='segmentation',\n",
    "                dimensions=neuroglancer.CoordinateSpace(\n",
    "                    names=['x', 'y', 'z'],\n",
    "                    units=['', '', ''],\n",
    "                    scales=[1, 1, 1],\n",
    "                    coordinate_arrays=[\n",
    "                    None, None, None\n",
    "                ]),\n",
    "            voxel_offset=(0, 0, 0)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add another raw image next to previous one and inverse colors with shader\n",
    "with viewer.txn() as s:\n",
    "    s.layers.append(\n",
    "            name='raw',\n",
    "            layer=neuroglancer.LocalVolume(\n",
    "                data=raw,\n",
    "                volume_type='image',\n",
    "                dimensions=neuroglancer.CoordinateSpace(\n",
    "                    names=['x', 'y', 'z'],\n",
    "                    units=['', '', ''],\n",
    "                    scales=[1, 1, 1],\n",
    "                    coordinate_arrays=[\n",
    "                    None, None, None\n",
    "                ]),\n",
    "                voxel_offset=(140, 0, 0),\n",
    "            ),\n",
    "            shader='''\n",
    "                void main() {\n",
    "                  float v = toRaw(getDataValue(0));\n",
    "                  v= 1.0-v;\n",
    "                  emitRGBA(vec4(v, 0.0, 0.0, v));\n",
    "                }\n",
    "            '''\n",
    "    )\n",
    "# check here for other shader ideas: https://github.com/google/neuroglancer/blob/master/src/neuroglancer/sliceview/image_layer_rendering.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViewerState({\"dimensions\": {\"x\": [1, \"\"], \"y\": [1, \"\"], \"z\": [1, \"\"]}, \"position\": [70, 70, 600], \"crossSectionScale\": 0.5040902295748241, \"projectionOrientation\": [-0.11960987001657486, -0.1577543020248413, 0.11780107021331787, 0.9731032848358154], \"projectionScale\": 816.1669961410847, \"layers\": [{\"type\": \"image\", \"source\": \"python://volume/8ec2ab6e5a0a3fa144a7e0f9c6e0f506fc5d3811.d589cf186d9c99c78b2d0c9eab89b982592886c9\", \"name\": \"raw\"}, {\"type\": \"segmentation\", \"source\": \"python://volume/8ec2ab6e5a0a3fa144a7e0f9c6e0f506fc5d3811.5a1fce0295d32d5915a443f27dd93e396699b47a\", \"tab\": \"segments\", \"segments\": [\"155\", \"170\", \"44\", \"444\", \"55\", \"56\"], \"segmentQuery\": \"56, 170, 444\", \"name\": \"gt_label\"}, {\"type\": \"image\", \"source\": \"python://volume/8ec2ab6e5a0a3fa144a7e0f9c6e0f506fc5d3811.c3d90482d744801013f6ca4bd413a2e2a6cc6f89\", \"shader\": \"\\n                void main() {\\n                  float v = toRaw(getDataValue(0));\\n                  v= 1.0-v;\\n                  emitRGBA(vec4(v, 0.0, 0.0, v));\\n                }\\n            \", \"name\": \"raw1\"}], \"selectedLayer\": {\"layer\": \"gt_label\", \"visible\": true}, \"layout\": \"4panel\"})\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "state = viewer.state\n",
    "saved_state = copy.deepcopy(state)\n",
    "print(last_state)\n",
    "# do some modifications\n",
    "with viewer.txn() as s:\n",
    "    s.layers['gt_label'].segments.update([44, 55, 155])\n",
    "    s.voxel_coordinates = [70, 70, 600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'53984971ae2a15b353786f220eeaefd7f2960ac3'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# revert back to saved state\n",
    "viewer.set_state(saved_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bind action keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got my-action\n",
      "  Mouse position: [ 86.350204  83.26     584.37317 ]\n",
      "  Layer selected values: Map({\"raw\": {\"value\": 0.3694581389427185}, \"gt_label\": {\"value\": \"339\"}, \"raw1\": {}})\n"
     ]
    }
   ],
   "source": [
    "num_actions = 0\n",
    "def my_action(s):\n",
    "    global num_actions\n",
    "    num_actions += 1\n",
    "    with viewer.config_state.txn() as st:\n",
    "      st.status_messages['hello'] = ('Got action %d: mouse position = %r' %\n",
    "                                     (num_actions, s.mouse_voxel_coordinates))\n",
    "    print('Got my-action')\n",
    "    print('  Mouse position: %s' % (s.mouse_voxel_coordinates,))\n",
    "    print('  Layer selected values: %s' % (s.selected_values,))\n",
    "viewer.actions.add('my-action', my_action)\n",
    "with viewer.config_state.txn() as s:\n",
    "    s.input_event_bindings.viewer['keyt'] = 'my-action'\n",
    "    s.status_messages['hello'] = 'Welcome to this example'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### screen shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8324e2724a540c2b95dd4cc94437c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05\\xa0\\x00\\x00\\x035\\x08\\x06\\x00\\x00\\x00\\x86\\xdbV\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Image\n",
    "screenshot = viewer.screenshot(size=[1000, 1000])\n",
    "screenshot_image = Image(value=screenshot.screenshot.image)\n",
    "screenshot_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layout = neuroglancer.row_layout(\n",
    "        [neuroglancer.LayerGroupViewer(layers=['raw', 'gt_label']),\n",
    "         neuroglancer.LayerGroupViewer(layers=['gt_label'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroglancer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metric_learning",
   "language": "python",
   "name": "metric_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}